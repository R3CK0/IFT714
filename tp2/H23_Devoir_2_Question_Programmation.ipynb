{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VSjS_XAbjQI"
      },
      "source": [
        "# Notebook pour la question de programmation du Devoir 2\n",
        "\n",
        "\n",
        "### Objectives d'apprentissage\n",
        "Dans ce problème, nous allons implémenter la régression logistique et la tester sur un jeu de données d'analyse des sentiments.\n",
        "\n",
        "### Code à écrire\n",
        "Recherchez le mot clé \"TODO\" et rajoutez votre code dans l'espace vide indiqué entre les commentaires du début et fin de votre solution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AslCbBsMbol6"
      },
      "source": [
        "### Pré-traitement des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOV13zuwihm6"
      },
      "source": [
        "#### Classe et fonction pour charger les données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlf4P1apdf-w"
      },
      "source": [
        "# Importer des bibliothèques\n",
        "import argparse\n",
        "import time\n",
        "\n",
        "# Définir une classe pour stocker un seul exemple (instance) de sentiment (words, label)\n",
        "class SentimentExample:\n",
        "    def __init__(self, words, label):\n",
        "        self.words = words\n",
        "        self.label = label\n",
        "\n",
        "    def __repr__(self):\n",
        "        return repr(self.words) + \"; label=\" + repr(self.label)\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.__repr__()\n",
        "\n",
        "\n",
        "# Lit les exemples de sentiments au format [0 ou 1]<TAB>[phrase brute] ; tokenise et nettoie les phrases.\n",
        "def read_sentiment_examples(infile):\n",
        "    f = open(infile, encoding='iso8859')\n",
        "    exs = []\n",
        "    for line in f:\n",
        "            fields = line.strip().split(\" \")\n",
        "            label = 0 if \"0\" in fields[0] else 1\n",
        "            exs.append(SentimentExample(fields[1:], label))\n",
        "    f.close()\n",
        "    return exs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "manEehMeimHD"
      },
      "source": [
        "#### *Charger* les données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTfKu8dwmFS_"
      },
      "source": [
        "# Monter le lecteur pour accéder aux fichiers dans gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFYGt6wcoc-C"
      },
      "source": [
        "#VOUS DEVEZ CHANGER LE CHEMIN DE train_file ET dev_file SELON OÙ VOUS LES STOCKEZ DANS VOTRE gdrive.\n",
        "\n",
        "#\"TODO\" changez le chemin pour train_file\n",
        "train_file = '/content/gdrive/MyDrive/Devoir_2/donnees/train.txt'\n",
        "#\"TODO\" changez le chemin pour dev_file\n",
        "dev_file = '/content/gdrive/MyDrive/Devoir_2/donnees/dev.txt'\n",
        "\n",
        "# Charger les données des fichiers\n",
        "train_exs = read_sentiment_examples(train_file)\n",
        "dev_exs = read_sentiment_examples(dev_file)\n",
        "n_pos = 0\n",
        "n_neg = 0\n",
        "for ex in train_exs:\n",
        "    if ex.label == 1:\n",
        "        n_pos += 1\n",
        "    else:\n",
        "        n_neg += 1\n",
        "print(\"%d train examples: %d positive, %d negative\" % (len(train_exs), n_pos, n_neg))\n",
        "print(\"%d dev examples\" % len(dev_exs))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulsaBn24p-LX"
      },
      "source": [
        "#### Indexer les exemples\n",
        "Cette section contient le code d'un indexeur (Indexer) qui est utile pour créer un mappage entre les mots et les index. Il a déjà été implémenté pour vous. Lisez-le et essayez de comprendre ce que font ses méthodes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck1X_FzPqMVk"
      },
      "source": [
        "# Bijection entre objets et entiers commençant à 0. Utile pour le mappage\n",
        "# étiquettes, attributs(features), etc. en coordonnées d'un espace vectoriel.\n",
        "\n",
        "# Cette classe crée un mapping entre des objets (ici des mots) et des index uniques\n",
        "# Par exemple : apple->1, banana->2, etc.\n",
        "\n",
        "class Indexer(object):\n",
        "    def __init__(self):\n",
        "        self.objs_to_ints = {}\n",
        "        self.ints_to_objs = {}\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str([str(self.get_object(i)) for i in range(0, len(self))])\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.__repr__()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.objs_to_ints)\n",
        "\n",
        "    # Renvoie l'objet correspondant à l'index particulier\n",
        "    def get_object(self, index):\n",
        "        if (index not in self.ints_to_objs):\n",
        "            return None\n",
        "        else:\n",
        "            return self.ints_to_objs[index]\n",
        "\n",
        "    def contains(self, object):\n",
        "        return self.index_of(object) != -1\n",
        "\n",
        "    # Renvoie -1 si l'objet n'est pas présent, l'index sinon\n",
        "    def index_of(self, object):\n",
        "        if (object not in self.objs_to_ints):\n",
        "            return -1\n",
        "        else:\n",
        "            return self.objs_to_ints[object]\n",
        "\n",
        "    # Ajoute l'objet à l'index s'il n'est pas présent, renvoie toujours un index non négatif\n",
        "    def add_and_get_index(self, object, add=True):\n",
        "        if not add:\n",
        "            return self.index_of(object)\n",
        "        if (object not in self.objs_to_ints):\n",
        "            new_idx = len(self.objs_to_ints)\n",
        "            self.objs_to_ints[object] = new_idx\n",
        "            self.ints_to_objs[new_idx] = object\n",
        "        return self.objs_to_ints[object]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaC07CdvlB-9"
      },
      "source": [
        "### Definir le modèle de régression logistique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0b4C1DImvuM"
      },
      "source": [
        "# Importer des bibliothèques\n",
        "from collections import Counter\n",
        "from typing import List\n",
        "import numpy as np\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSCzfcnMjm-r"
      },
      "source": [
        "#### Definir l'extracteur d'attributs/features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eGn0zEOnLOq"
      },
      "source": [
        "# Type de base d'extraction d'attributs (features). Prend un exemple et renvoie une liste indexée d'attributs.\n",
        "class FeatureExtractor(object):\n",
        "    # Extraire les attributs (features). Inclut un indicateur add_to_indexer pour contrôler si l'indexeur doit être étendu.\n",
        "    # Au moment du test, tous les attributs/features inconnus (non-vu auparavant) doivent être ignorés, mais au moment de l'entrainement,\n",
        "    # nous voulons probablement continuer à l'étendre.\n",
        "    def extract_features(self, ex, add_to_indexer):\n",
        "        raise Exception(\"Don't call me, call my subclasses\")\n",
        "\n",
        "\n",
        "# Extrait les attributs (features) unigramme sac-de-mots (BOW) d'une phrase.\n",
        "# Vous pouvez considérer un unigramme comme un mot unique (par exemple \"love\", \"you\").\n",
        "# C'est à vous de décider comment vous voulez gérer les comptages\n",
        "class UnigramFeatureExtractor(FeatureExtractor):\n",
        "    def __init__(self, indexer: Indexer):\n",
        "        self.indexer = indexer\n",
        "\n",
        "    def extract_features(self, ex, add_to_indexer=False):\n",
        "        features = Counter()\n",
        "        for w in ex.words:\n",
        "            feat_idx = self.indexer.add_and_get_index(w) \\\n",
        "                if add_to_indexer else self.indexer.index_of(w)\n",
        "            if feat_idx != -1:\n",
        "                features[feat_idx] += 1.0\n",
        "        return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLEP8hSXnvP5"
      },
      "source": [
        "#### Definir les classifieurs de base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CgFsVR4nyGN"
      },
      "source": [
        "# Type de base du classificateur de sentiment\n",
        "class SentimentClassifier(object):\n",
        "    # Makes a prediction for the given example\n",
        "    def predict(self, ex: SentimentExample):\n",
        "        raise Exception(\"Don't call me, call my subclasses\")\n",
        "\n",
        "\n",
        "# Prédit toujours la classe positive\n",
        "class AlwaysPositiveClassifier(SentimentClassifier):\n",
        "    def predict(self, ex: SentimentExample):\n",
        "        return 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKEB5sYeodoh"
      },
      "source": [
        "#### Classe régression logistique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kcp4Wkbqoiuu"
      },
      "source": [
        "class LogisticRegressionClassifier(SentimentClassifier):\n",
        "    def __init__(self, feat_extractor: FeatureExtractor, train_examples, num_iters=50, reg_lambda=0.0, learning_rate=0.1):\n",
        "        # TODO : Initialiser le modèle de régression logistique\n",
        "        \n",
        "        # Arguments : feat_extractor est unigram, train_examples est un jeu de données d'entrainement\n",
        "        # num_iters est le nombre d'époques, reg_lambda est le paramètre de régularisation\n",
        "        # learning_rate est le taux d'apprentissage utilisé dans la descente de gradient\n",
        "        \n",
        "        # ÉTAPE 1 : Définissez les variables pour les poids et les biais, et initialisez-les à zéro\n",
        "        \n",
        "        # ÉTAPE 2 : Appelez la fonction train(). (Cela a déjà été fait pour vous)\n",
        "\n",
        "        ##### DÉBUT DE LA SOLUTION #####\n",
        "        \n",
        "        ##### FIN DE LA SOLUTION  #####\n",
        "\n",
        "        self.train(feat_extractor, train_examples, num_iters, reg_lambda, learning_rate)\n",
        "\n",
        "\n",
        "    def train(self, feat_extractor: FeatureExtractor, train_examples, num_iters=50, reg_lambda=0.0, learning_rate=0.1):\n",
        "        # TODO : fonction d'entraînement du modèle de régression logistique.\n",
        "        # Utilisez une descente de gradient stochastique.\n",
        "        \n",
        "\n",
        "        ##### DÉBUT DE LA SOLUTION #####\n",
        "\n",
        "        ##### FIN DE LA SOLUTION  #####    \n",
        "\n",
        "    def predict(self, ex):\n",
        "        # TODO : prédiction du modèle de régression logistique pour un seul exemple\n",
        "        \n",
        "        ##### DÉBUT DE LA SOLUTION #####\n",
        "\n",
        "        ##### FIN DE LA SOLUTION  #####"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cesGHOCipwgL"
      },
      "source": [
        "#### Fonction d'entrainement pour la régression logisique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLwZpsU3qC31"
      },
      "source": [
        "# Entrainer un modèle de régression logsitique sur les exemples d'entrainement en utilisant le FeatureExtractor, tous donnés en paramètres.\n",
        "def train_lr(train_exs: List[SentimentExample], feat_extractor: FeatureExtractor, reg_lambda) -> LogisticRegressionClassifier:\n",
        "    # TODO : fonction d'entraînement du modèle de régression logistique.\n",
        "    # Remplissez le feature_extractor.\n",
        "    # Initialisez et renvoiez un objet d'instance LogisticRegressionClassifier\n",
        "    \n",
        "    ##### DÉBUT DE LA SOLUTION #####\n",
        "\n",
        "    ##### FIN DE LA SOLUTION  #####"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMHrP9X7qItd"
      },
      "source": [
        "# POINT D'ENTREE PRINCIPAL pour vos modifications. \n",
        "# Entraîne et retourne un des modèles possibles selon les options passées.\n",
        "def train_model(feature_type, model_type, train_exs, reg_lambda=0.0):\n",
        "    \n",
        "    # Initialize feature extractor\n",
        "    if feature_type == \"unigram\":\n",
        "        feat_extractor = UnigramFeatureExtractor(Indexer())\n",
        "    else:\n",
        "        raise Exception(\"Pass unigram\")\n",
        "\n",
        "    # Train the model\n",
        "    if model_type == \"AlwaysPositive\":\n",
        "        model = AlwaysPositiveClassifier()\n",
        "    elif model_type == \"LogisticRegression\":\n",
        "        model = train_lr(train_exs, feat_extractor, reg_lambda=reg_lambda)\n",
        "    else:\n",
        "        raise Exception(\"Pass AlwaysPositive or LogisticRegression\")\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO3EqbavuJpz"
      },
      "source": [
        "### Fonctions pour l'évaluation du modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgTqmbGcuM3f"
      },
      "source": [
        "# Évalue un classificateur donné sur les exemples donnés\n",
        "def evaluate(classifier, exs):\n",
        "    return print_evaluation([ex.label for ex in exs], [classifier.predict(ex) for ex in exs])\n",
        "\n",
        "\n",
        "# Imprime la précision en comparant la vérité du terrain (ground truth) - golds - et les prédictions, chacune étant une séquence d'étiquettes 0/1.\n",
        "def print_evaluation(golds, predictions):\n",
        "    num_correct = 0\n",
        "    num_pos_correct = 0\n",
        "    num_pred = 0\n",
        "    num_gold = 0\n",
        "    num_total = 0\n",
        "    if len(golds) != len(predictions):\n",
        "        raise Exception(\"Mismatched gold/pred lengths: %i / %i\" %\n",
        "                        (len(golds), len(predictions)))\n",
        "    for idx in range(0, len(golds)):\n",
        "        gold = golds[idx]\n",
        "        prediction = predictions[idx]\n",
        "        if prediction == gold:\n",
        "            num_correct += 1\n",
        "        if prediction == 1:\n",
        "            num_pred += 1\n",
        "        if gold == 1:\n",
        "            num_gold += 1\n",
        "        if prediction == 1 and gold == 1:\n",
        "            num_pos_correct += 1\n",
        "        num_total += 1\n",
        "\n",
        "    print(\"Accuracy: %i / %i = %.2f %%\" %\n",
        "          (num_correct, num_total,\n",
        "           num_correct * 100.0 / num_total))\n",
        "    return num_correct * 100.0 / num_total\n",
        "    \n",
        "# ENTRÉE PRINCIPALE POUR L'ÉVALUATION sur les jeux de données d'entrainement et de développement\n",
        "def eval_train_dev(model):\n",
        "    print(\"===== Train Accuracy =====\")\n",
        "    train_acc = evaluate(model, train_exs)\n",
        "    print(\"===== Dev Accuracy =====\")\n",
        "    eval_acc = evaluate(model, dev_exs)\n",
        "    return [train_acc, eval_acc]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwrQ1_lHv-Co"
      },
      "source": [
        "### Évaluation du modèle avec une représentation unigramme Bag-of-Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1KNbz32wwws"
      },
      "source": [
        "# Évaluer la régression logistique avec des attributs unigrammes\n",
        "lr_unigram_model = train_model('unigram', 'LogisticRegression', train_exs)\n",
        "eval_train_dev(lr_unigram_model)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}